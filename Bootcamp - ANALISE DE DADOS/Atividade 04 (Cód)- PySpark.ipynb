{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão do Spark: 3.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/26 13:49:57 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Inicializa o SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ExemploSpark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Verifica a versão do Spark para confirmar a configuração\n",
    "print(\"Versão do Spark:\", spark.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n",
    "# Torna o pyspark \"importável\"\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/08/26 13:49:57 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7db75398bec0>\n",
      "+---+--------------+-----+----------+-------+-------------------+-----------------+\n",
      "| ID|          Nome|Idade|      Área|Salário|Data de Contratação|Status de Emprego|\n",
      "+---+--------------+-----+----------+-------+-------------------+-----------------+\n",
      "|  1|    João Silva|   29|Financeiro|   5500|         01/02/2020|            Ativo|\n",
      "|  2|   Maria Souza|   30|        RH|   4800|         15-03-2019|            ativo|\n",
      "|  3|Carlos Pereira| NULL| Finaceiro|   6200|         2020/04/01|            Ativo|\n",
      "|  4|     Ana Clara|   27| Marketing|   4800|         12/06/2018|            Ativo|\n",
      "|  5|  Fabio Santos|   31|      NULL|   5500|         20-11-2017|            ativo|\n",
      "|  6|   Sandra Lima|   28|        RH|   NULL|         05-05-2020|            Ativo|\n",
      "|  7|    José Alves|   34| Marketing|   5400|         2018/02/01|          inativo|\n",
      "|  8| Luciana Costa|   30|Financeiro|R$ 5200|         01.01.2019|            Ativo|\n",
      "|  9| Paulo Ricardo| NULL| Finaceiro|   6100|         12/12/2020|          Inativo|\n",
      "| 10| Fernanda Dias|   29|        RH|   4800|               NULL|            Ativo|\n",
      "|  1|    João Silva|   29|Financeiro|   5500|         01/02/2020|            Ativo|\n",
      "+---+--------------+-----+----------+-------+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Criar uma sessão Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Exemplo PySpark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Verificar se a sessão foi criada corretamente\n",
    "print(spark)\n",
    "\n",
    "arquivo = \"/home/wermelingerv/Documentos/GitHub/SoulCode/Bootcamp - ANALISE DE DADOS/Banco de Dados_base_suja.csv\"\n",
    "\n",
    "df_base_suja = spark\\\n",
    "    .read.format(\"csv\")\\\n",
    "    .option(\"inferSchema\", \"True\")\\\n",
    "    .option(\"header\", \"True\")\\\n",
    "    .csv(arquivo)\n",
    "df_base_suja.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|      Area|Status de Emprego|\n",
      "+----------+-----------------+\n",
      "|financeiro|            ativo|\n",
      "|        rh|            ativo|\n",
      "| finaceiro|            ativo|\n",
      "| marketing|            ativo|\n",
      "|      NULL|            ativo|\n",
      "|        rh|            ativo|\n",
      "| marketing|          inativo|\n",
      "|financeiro|            ativo|\n",
      "| finaceiro|          inativo|\n",
      "|        rh|            ativo|\n",
      "|financeiro|            ativo|\n",
      "+----------+-----------------+\n",
      "\n",
      "+---+-------------+-----+----------+-------+-------------------+-----------------+\n",
      "| ID|         Nome|Idade|      Área|Salário|Data de Contratação|Status de Emprego|\n",
      "+---+-------------+-----+----------+-------+-------------------+-----------------+\n",
      "|  1|   João Silva|   29|Financeiro|   5500|         01/02/2020|            Ativo|\n",
      "|  2|  Maria Souza|   30|        RH|   4800|         15-03-2019|            ativo|\n",
      "|  4|    Ana Clara|   27| Marketing|   4800|         12/06/2018|            Ativo|\n",
      "|  6|  Sandra Lima|   28|        RH|   NULL|         05-05-2020|            Ativo|\n",
      "|  7|   José Alves|   34| Marketing|   5400|         2018/02/01|          inativo|\n",
      "|  8|Luciana Costa|   30|Financeiro|R$ 5200|         01.01.2019|            Ativo|\n",
      "| 10|Fernanda Dias|   29|        RH|   4800|               NULL|            Ativo|\n",
      "|  1|   João Silva|   29|Financeiro|   5500|         01/02/2020|            Ativo|\n",
      "+---+-------------+-----+----------+-------+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#1. Análise de Consistência de Dados: \n",
    "# Identificar e corrigir inconsistências nos valores de Área e Status de Emprego(e.g.,diferenças de maiúsculas/minúsculas).\n",
    "\n",
    "# Renomear a coluna \"Área\" para \"Area\" e converter as colunas para minúsculas em uma única linha\n",
    "status_area = df_base_suja.withColumnRenamed(\"Área\", \"Area\") \\\n",
    "    .selectExpr(\"lower(Area) as Area\", \"lower(`Status de Emprego`) as `Status de Emprego`\")\n",
    "# Mostrar o resultado\n",
    "status_area.show()\n",
    "\n",
    "# 2. Limpeza de Dados Faltantes: Detectar e tratar os valores ausentes na coluna \"Idade\" e \"Área\".\n",
    "# Contar valores ausentes na coluna \"Idade\"\n",
    "df_base_suja.select(count(when(col(\"Idade\").isNull() | isnan(col(\"Idade\")), \"Idade\")).alias(\"Idade Missing\"))\n",
    "# Contar valores ausentes na coluna \"Área\"\n",
    "df_base_suja.select(count(when(col(\"Área\").isNull() | isnan(col(\"Área\")), \"Área\")).alias(\"Área Missing\"))\n",
    "# Remover linhas onde \"Idade\" ou \"Área\" tem valores ausentes\n",
    "df_cleaned = df_base_suja.dropna(subset=[\"Idade\", \"Área\"])\n",
    "# Verificar se os valores ausentes foram removidos\n",
    "df_cleaned.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+----------------------+------------------------+\n",
      "|      Area|    Média de Idade|Desvio Padrão de Idade|Contagem de Funcionários|\n",
      "+----------+------------------+----------------------+------------------------+\n",
      "|financeiro|29.333333333333332|    0.5773502691896258|                       3|\n",
      "| marketing|              30.5|     4.949747468305833|                       2|\n",
      "|        rh|              29.0|                   1.0|                       3|\n",
      "+----------+------------------+----------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Renomear a coluna \"Área\" para \"Area\" e converter as colunas para minúsculas, incluindo \"Idade\"\n",
    "df_cleaned = df_base_suja.withColumnRenamed(\"Área\", \"Area\").selectExpr(\"lower(Area) as Area\", \"lower(`Status de Emprego`) as `Status de Emprego`\", \"Idade\")\n",
    "\n",
    "# 2. Detectar e tratar os valores ausentes na coluna \"Idade\" e \"Area\"\n",
    "df_cleaned = df_cleaned.dropna(subset=[\"Idade\", \"Area\"])\n",
    "\n",
    "# 3. Analisar a distribuição da idade dos funcionários por departamento\n",
    "df_age_distribution = df_cleaned.groupBy(\"Area\").agg(\n",
    "        avg(\"Idade\").alias(\"Média de Idade\"),\n",
    "        stddev(\"Idade\").alias(\"Desvio Padrão de Idade\"),\n",
    "        count(\"Idade\").alias(\"Contagem de Funcionários\"))\n",
    "\n",
    "# Mostrar o resultado da análise de distribuição de idade por departamento\n",
    "df_age_distribution.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+------------------------+------------------+\n",
      "|      Area|Média de Salário|Desvio Padrão de Salário|Mediana de Salário|\n",
      "+----------+----------------+------------------------+------------------+\n",
      "|financeiro|          5500.0|                     0.0|            5500.0|\n",
      "| marketing|          5100.0|      424.26406871192853|            4800.0|\n",
      "|        rh|          4800.0|                     0.0|            4800.0|\n",
      "| finaceiro|          6150.0|       70.71067811865476|            6100.0|\n",
      "+----------+----------------+------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Renomear a coluna \"Área\" para \"Area\" e converter as colunas para minúsculas\n",
    "df_cleaned = df_base_suja.withColumnRenamed(\"Área\", \"Area\").selectExpr(\"lower(Area) as Area\", \"lower(`Salário`) as Salario\")\n",
    "\n",
    "# 2. Detectar e tratar os valores ausentes na coluna \"Salário\" e \"Area\"\n",
    "df_cleaned = df_cleaned.dropna(subset=[\"Salario\", \"Area\"])\n",
    "\n",
    "# 4. Calcular a média, mediana e desvio padrão dos salários por departamento\n",
    "df_salary_stats = df_cleaned.groupBy(\"Area\").agg(\n",
    "        avg(\"Salario\").alias(\"Média de Salário\"),\n",
    "        stddev(\"Salario\").alias(\"Desvio Padrão de Salário\"),\n",
    "        percentile_approx(\"Salario\", 0.5).alias(\"Mediana de Salário\"))\n",
    "\n",
    "# Mostrar o resultado da análise de salário por departamento\n",
    "df_salary_stats.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|      Area|Mediana|\n",
      "+----------+-------+\n",
      "|financeiro| 5500.0|\n",
      "| marketing| 4800.0|\n",
      "|        rh| 4800.0|\n",
      "| finaceiro| 6100.0|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calcular a mediana dos salários por departamento\n",
    "salario_dep_mediana = df_cleaned.groupBy('Area').agg(expr('percentile_approx(Salario, 0.5)').alias('Mediana'))\n",
    "salario_dep_mediana.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+-----------+-----------+\n",
      "|Area|Salario|Lower_Bound|Upper_Bound|\n",
      "+----+-------+-----------+-----------+\n",
      "+----+-------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Análise de Outliers: Identificar salários que estão fora do padrão (outliers) para cada departamento.\n",
    "#. Calcular o primeiro quartil (Q1) e o terceiro quartil (Q3) para os salários por departamento\n",
    "df_quartiles = df_cleaned.groupBy(\"Area\").agg(\n",
    "        expr(\"percentile_approx(Salario, 0.25)\").alias(\"Q1\"),\n",
    "        expr(\"percentile_approx(Salario, 0.75)\").alias(\"Q3\")\n",
    "    )\n",
    "\n",
    "##. Calcular o IQR (Q3 - Q1)\n",
    "df_quartiles = df_quartiles.withColumn(\"IQR\", col(\"Q3\") - col(\"Q1\"))\n",
    "\n",
    "###. Determinar os limites inferior e superior para detectar outliers\n",
    "df_quartiles = df_quartiles.withColumn(\"Lower_Bound\", col(\"Q1\") - 1.5 * col(\"IQR\")) \\\n",
    "    .withColumn(\"Upper_Bound\", col(\"Q3\") + 1.5 * col(\"IQR\"))\n",
    "\n",
    "####. Juntar os limites calculados com o dataframe original para identificar os outliers\n",
    "df_with_outliers = df_cleaned.join(df_quartiles, on=\"Area\")\n",
    "\n",
    "#####. Filtrar os outliers (salários fora dos limites inferior e superior)\n",
    "df_outliers = df_with_outliers.filter(\n",
    "    (col(\"Salario\") < col(\"Lower_Bound\")) | (col(\"Salario\") > col(\"Upper_Bound\"))\n",
    ")\n",
    "\n",
    "###.###.Mostrar os outliers identificados\n",
    "df_outliers.select(\"Area\", \"Salario\", \"Lower_Bound\", \"Upper_Bound\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
