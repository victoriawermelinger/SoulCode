{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A criação de um **Google Colab** para extrair dados de um **bucket no Google Cloud Storage** e de um banco de dados **Google Cloud SQL** envolve o uso de bibliotecas específicas do Python para conectar-se a esses serviços. Abaixo está um passo a passo com exemplos de código para cada etapa.\n",
    "\n",
    "### **Passos para criar o Colab:**\n",
    "\n",
    "#### 1. **Configurar o ambiente**\n",
    "Certifique-se de que você tem as bibliotecas necessárias instaladas no Colab.\n",
    "\n",
    "```python\n",
    "# Instalar bibliotecas necessárias\n",
    "!pip install google-cloud-storage\n",
    "!pip install mysql-connector-python\n",
    "```\n",
    "\n",
    "#### 2. **Autenticação no Google Cloud**\n",
    "Antes de acessar o Google Cloud Storage ou Cloud SQL, você precisa se autenticar usando uma chave de conta de serviço.\n",
    "\n",
    "```python\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Conectar ao Google Cloud\n",
    "!gcloud auth login\n",
    "\n",
    "# Se você estiver usando um arquivo de chave JSON para autenticação\n",
    "from google.oauth2 import service_account\n",
    "credentials = service_account.Credentials.from_service_account_file('path/to/key.json')\n",
    "```\n",
    "\n",
    "#### 3. **Extração de dados do Google Cloud Storage**\n",
    "\n",
    "Aqui está o código para extrair arquivos (por exemplo, CSV) do bucket do Google Cloud Storage:\n",
    "\n",
    "```python\n",
    "from google.cloud import storage\n",
    "\n",
    "# Definir o nome do bucket e o arquivo a ser extraído\n",
    "bucket_name = 'seu-bucket'\n",
    "source_blob_name = 'dados_brutos/seu_arquivo.csv'\n",
    "destination_file_name = '/tmp/seu_arquivo.csv'\n",
    "\n",
    "# Criar cliente de Storage\n",
    "client = storage.Client(credentials=credentials)\n",
    "\n",
    "# Conectar ao bucket e baixar o arquivo\n",
    "bucket = client.bucket(bucket_name)\n",
    "blob = bucket.blob(source_blob_name)\n",
    "blob.download_to_filename(destination_file_name)\n",
    "\n",
    "print(f'Arquivo {source_blob_name} baixado para {destination_file_name}.')\n",
    "```\n",
    "\n",
    "Após o download do arquivo, você pode ler os dados usando **Pandas**:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar os dados para um DataFrame\n",
    "df = pd.read_csv('/tmp/seu_arquivo.csv')\n",
    "\n",
    "# Exibir as primeiras linhas para verificar os dados\n",
    "df.head()\n",
    "```\n",
    "\n",
    "#### 4. **Extração de dados do Google Cloud SQL**\n",
    "\n",
    "Para se conectar ao **Google Cloud SQL** (MySQL), você precisará configurar a conexão e passar as credenciais:\n",
    "\n",
    "```python\n",
    "import mysql.connector\n",
    "\n",
    "# Definir parâmetros de conexão\n",
    "connection = mysql.connector.connect(\n",
    "    host=\"seu-endereco-ip-publico\",  # Endereço IP da instância MySQL\n",
    "    user=\"seu-usuario\",\n",
    "    password=\"sua-senha\",\n",
    "    database=\"seu-banco-de-dados\"\n",
    ")\n",
    "\n",
    "# Criar cursor para executar consultas\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Executar consulta e carregar dados\n",
    "query = \"SELECT * FROM sua_tabela\"\n",
    "cursor.execute(query)\n",
    "\n",
    "# Trazer os resultados e convertê-los em DataFrame\n",
    "result = cursor.fetchall()\n",
    "df_sql = pd.DataFrame(result, columns=cursor.column_names)\n",
    "\n",
    "# Fechar a conexão\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "# Exibir as primeiras linhas\n",
    "df_sql.head()\n",
    "```\n",
    "\n",
    "#### 5. **Transformações (ETL)**\n",
    "Depois de extrair os dados, você pode realizar as transformações necessárias:\n",
    "\n",
    "```python\n",
    "# Exemplo de criação de uma nova coluna\n",
    "df['nova_coluna'] = df['coluna_existente'] * 2\n",
    "\n",
    "# Exemplo de agrupamento\n",
    "df_grouped = df.groupby('categoria').agg({'valor': 'sum'}).reset_index()\n",
    "\n",
    "# Exibir os dados transformados\n",
    "df_grouped.head()\n",
    "```\n",
    "\n",
    "#### 6. **Carga dos dados no Google BigQuery**\n",
    "Após as transformações, você pode carregar os dados para o **Google BigQuery**. Primeiro, instale a biblioteca:\n",
    "\n",
    "```python\n",
    "!pip install --upgrade google-cloud-bigquery\n",
    "```\n",
    "\n",
    "Agora, carregue os dados:\n",
    "\n",
    "```python\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Definir nome do projeto e dataset\n",
    "project_id = 'seu-projeto'\n",
    "dataset_id = 'seu_dataset'\n",
    "table_id = 'sua_tabela'\n",
    "\n",
    "# Criar cliente BigQuery\n",
    "client = bigquery.Client(credentials=credentials, project=project_id)\n",
    "\n",
    "# Carregar o DataFrame para BigQuery\n",
    "job = client.load_table_from_dataframe(df_grouped, f'{project_id}.{dataset_id}.{table_id}')\n",
    "\n",
    "# Aguardar o término do job\n",
    "job.result()\n",
    "\n",
    "print(f'Dados carregados na tabela {table_id} com sucesso.')\n",
    "```\n",
    "\n",
    "#### 7. **Comentando o código**\n",
    "\n",
    "Certifique-se de que cada parte do código tenha comentários claros explicando o que está acontecendo:\n",
    "\n",
    "```python\n",
    "# Baixar arquivo do Google Cloud Storage e carregar em um DataFrame\n",
    "bucket_name = 'seu-bucket'\n",
    "source_blob_name = 'dados_brutos/seu_arquivo.csv'\n",
    "destination_file_name = '/tmp/seu_arquivo.csv'\n",
    "\n",
    "client = storage.Client(credentials=credentials)\n",
    "bucket = client.bucket(bucket_name)\n",
    "blob = bucket.blob(source_blob_name)\n",
    "blob.download_to_filename(destination_file_name)\n",
    "\n",
    "print(f'Arquivo {source_blob_name} baixado para {destination_file_name}.')\n",
    "```\n",
    "\n",
    "### **Conclusão**\n",
    "\n",
    "Este exemplo mostra como você pode organizar seu código no Google Colab para extrair dados tanto do **Google Cloud Storage** quanto do **Google Cloud SQL**, realizar transformações e carregar esses dados no **Google BigQuery**. Certifique-se de que todos os códigos estejam comentados para garantir que o avaliador possa entender o que foi feito em cada etapa."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
